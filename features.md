| Feature                                   | Description                                                                                                     | Progress (0–5) | Value / Strengths                                                                                                                                                                                                                                    | Where it makes most sense (use cases)                                                                                                                                                                                      |
|-------------------------------------------|-----------------------------------------------------------------------------------------------------------------|----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Volumetric Dense SLAM system              | Builds a dense 3D representation of the environment, not just sparse keypoints                                 | 5              | Does not skip “uninteresting” but dangerous objects (chairs, people, furniture). Much better obstacle reasoning and can address hidden problems like mirrors/glass where feature SLAM often fails. Can later be trimmed down to sparser variants.     | Safety-critical navigation: drones and robots in cluttered or reflective environments (warehouses, factories, mines, power-line and building inspection, street-analysis rigs, assistive devices like Lumen-style headsets). |
| GPU-accelerated                           | Highly parallelizable pipeline that runs on discrete and embedded GPUs                                          | 5              | Huge speedups: loop closure ~10–12× faster and data sensing hundreds× faster on GPU. Can parallelize mapping, integration, loop closure, etc. For single-GPU devices you can briefly pause the robot, run loop closure, then continue.              | Edge or onboard devices with at least one GPU (drones, robots, vehicles), and post-production/cloud pipelines where lots of GPU cores can be used in parallel.                                                             |
| Volumetric representation with voxels + TSDF/ESDF | Environment stored as voxel grid using TSDF for fast initial fusion and ESDF for accurate signed distances      | 5              | Hot technique in modern SLAM: for every point in free space you know the distance to the nearest surface, enabling very fast collision checks and safe/unsafe volume queries, which accelerates local planning and navigation.                       | Precise navigation in tight or complex spaces; infrastructure and road inspection where geometric detail (cracks, bumps, edges) matters; environments where you need robust free-space queries.                            |
| GPU-oriented data layout                  | Sensor data is standardized as depth frames and laid out to be GPU-friendly                                    | 5              | Sensor-agnostic: LiDAR, stereo cameras and depth cameras are all converted into the same “frame of distances”. Layout minimizes cache/memory issues and maximizes GPU efficiency and power usage at high sensing rates (~100 Hz).                    | Multi-sensor robots and drones that must fuse LiDAR + cameras; embedded GPU platforms where every watt counts; high-frequency sensing setups.                                                                             |
| Global pose-graph optimization            | Global pose-graph / loop-closure optimization over overlapping local sub-maps                                  | 5              | Strong reduction of drift and improved global consistency over long trajectories. GPU-assisted loop-closure solver (GTSAM-like) can also be offloaded/ported to CPU. Loop closure can run asynchronously or while the robot pauses briefly.          | Large-scale mapping: big buildings, campuses, mines, cities; repeated loops (logistics trucks, warehouse robots); long-duration missions where accumulated drift is a problem.                                            |
| Data-flow design                          | System can load only the map parts that are needed and keep sensing / improvement as separate flows            | 5              | Enables splitting responsibilities across hardware (GPU vs CPU vs cloud). Supports streaming maps from a server and keeping heavy optimizations in the background while the robot keeps using a stable version of the map.                         | SLAM-as-a-Service backends, post-production pipelines, and fleets where robots upload data and receive improved maps later; edge setups where onboard compute is tight.                                                   |
| Swap between maps                         | Robot can use and switch between different maps; memory usage may increase                                     | 5              | Similar to Roomba: operators can choose which map/area to use (“only kitchen + office”, “don’t go here”). Not common in academic SLAM but very pragmatic. Opens up scenario-specific or customer-specific maps.                                      | Service robots (home, hotel, office), drones reused across multiple sites or floors, environments with seasonal/layout changes, or different mission profiles (inspection map vs navigation map).                           |
| Async data sensing and map augmentation   | System collects data and stores it independently, then uses it later to improve the map                        | 5              | Robot can navigate with an “old” but safe map while new sensor data is fused offline or on another processor (CPU, second GPU, or cloud). Decouples heavy optimization from real-time navigation, ideal for single-GPU or resource-limited devices. | Continuous infrastructure inspection (roads, power lines, mines), long-term deployments where environments evolve (construction, farms), customers uploading data to a SLAM-as-a-Service platform for better maps.        |
| Level of details                          | Can generate and serve lower-quality maps from a high-quality master map                                       | 5              | Like video resolutions (1080p → 480p): you can downscale maps for lighter hardware or to speed up reaction time. Supports peripheral-vision-style low-res maps for fast obstacle avoidance, and high-res maps where detail is needed.              | Swarms of small drones backed by a heavier base station; lightweight robots that must reserve GPU for AI/vision; any use case requiring very fast reactions more than perfect geometry.                                   |
